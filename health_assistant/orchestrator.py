import uuid
from logging_setup import LoggerSetup
from database_manager import DatabaseManager
from elasticsearch_indexer import ElasticsearchIndexer
from prompt_builder import PromptBuilder
import prompt_templates as templates
from search_service import SearchService
from llm_service import LLMService
from response_evaluator import ResponseEvaluator
from cost_calculator import CostCalculator


class QueryOrchestrator:
    """
    Orchestrates the process of querying the LLM, which includes searching the Elasticsearch index,
    building the query prompt, and interacting with the LLM service.

    Attributes:
        es_client (Elasticsearch): The Elasticsearch client used for searching the index.
        llm_service (LLMService): The LLM service used to query the language model.
    """

    def __init__(self, logger, es_client, llm_service):
        """
        Initializes the QueryOrchestrator with the given Elasticsearch client and LLM service.

        Args:
            es_client (Elasticsearch): The Elasticsearch client used for searching the index.
            llm_service (LLMService): The LLM service used to query the language model.
        """
        self.es_client = es_client
        self.llm_service = llm_service
        self.logger = logger

    def process_query(self, question):
        """
        Processes a query by searching the Elasticsearch index, building a prompt, and querying the LLM.

        Args:
            context (str): The context for the question, which may provide additional background information.
            question (str): The question to be asked to the LLM.

        Returns:
            tuple: A tuple containing the LLM's response and the token statistics from the query.
        """
        # Search the Elasticsearch index with the user's question
        search_service = SearchService(logger=self.logger, es_client=self.es_client)
        search_results = search_service.search(query=question)

        # Build the prompt using search results and provided context
        question_prompt_builder = PromptBuilder(templates.QUESTION_PROMPT_TEMPLATE)
        context_data = question_prompt_builder.create_prompt_context(search_results)
        question_prompt = question_prompt_builder.build_prompt(
            question=question,
            answer=context_data["answer"],
            focus_area=context_data["focus_area"],
            source=context_data["source"],
        )

        # Query the LLM with the constructed prompt
        response, token_stats = self.llm_service.query_llm(prompt=question_prompt)

        return response, token_stats


class EvaluationOrchestrator:
    """
    Orchestrates the evaluation of the LLM's response, determining its relevance and gathering token statistics.

    Attributes:
        llm_service (LLMService): The LLM service used to query the language model for evaluation.
    """

    def __init__(self, logger, llm_service):
        """
        Initializes the EvaluationOrchestrator with the given LLM service.

        Args:
            llm_service (LLMService): The LLM service used to query the language model for evaluation.
        """
        self.llm_service = llm_service
        self.logger = logger

    def evaluate_response(self, question, answer):
        """
        Evaluates the relevance of the LLM's response to a given question.

        Args:
            question (str): The original question posed to the LLM.
            answer (str): The response generated by the LLM.

        Returns:
            tuple: A tuple containing the evaluation result (a dictionary) and the token statistics.
        """
        evaluator = ResponseEvaluator(
            logger=self.logger,
            llm_service=self.llm_service,
            prompt_builder=PromptBuilder(templates.EVALUATION_PROMPT_TEMPLATE),
        )
        evaluation_result, token_stats = evaluator.evaluate_relevance(question, answer)
        return evaluation_result, token_stats


class FeedbackOrchestrator:
    """
    Orchestrates the process of submitting user feedback, including like/dislike responses and additional comments.

    Attributes:
        db_manager (DatabaseManager): The database manager responsible for saving feedback data.
    """

    def __init__(self, db_manager):
        """
        Initializes the FeedbackOrchestrator with the given DatabaseManager.

        Args:
            db_manager (DatabaseManager): The database manager responsible for saving feedback data.
        """
        self.db_manager = db_manager

    def submit_feedback(self, conversation_id, feedback, additional_feedback):
        """
        Submits feedback for a given conversation, including a like/dislike and optional additional comments.

        Args:
            conversation_id (str): The unique identifier for the conversation.
            feedback (str): The feedback provided by the user, either "Like" or "Dislike".
            additional_feedback (str): Optional additional feedback provided by the user.
        """
        # Convert the feedback to a numerical value for storage
        # TODO adapt to feedback format of the app
        feedback_value = 1 if feedback == "Like" else -1

        # Save the feedback to the database
        self.db_manager.save_feedback(
            conversation_id=conversation_id,
            feedback=feedback_value,
            timestamp=None,  # Assuming current timestamp is used if None
        )

        if additional_feedback:
            # Save additional feedback, if provided (implement saving as needed)
            self.db_manager.save_feedback(
                conversation_id=conversation_id,
                feedback=feedback_value,
                timestamp=None,  # Assuming current timestamp is used if None
            )


class CostCalculationOrchestrator:
    """
    Orchestrates the calculation of the cost associated with querying the LLM, based on token usage.

    Attributes:
        cost_calculator (CostCalculator): The cost calculator used to determine the OpenAI API cost.
    """

    def __init__(self, logger):
        """
        Initializes the CostCalculationOrchestrator with a CostCalculator.
        """
        self.cost_calculator = CostCalculator(logger=logger)

    def calculate_cost(self, token_stats):
        """
        Calculates the cost of the LLM query based on the provided token statistics.

        Args:
            token_stats (dict): A dictionary containing token usage statistics from the LLM query.

        Returns:
            float: The calculated cost of the LLM query.
        """
        cost = self.cost_calculator.calculate_openai_cost(token_stats)
        return cost


# Main Orchestrator that integrates all sub-orchestrators
class MainOrchestrator:
    def __init__(self):
        logger_setup = LoggerSetup()
        self.logger = logger_setup.get_logger()

        self.db_manager = DatabaseManager(logger=self.logger)
        self.db_manager.init_db()

        indexer = ElasticsearchIndexer(logger=self.logger)
        self.es_client, self.index_name = indexer.load_and_index_data()

        self.llm_service = LLMService(logger=self.logger)
        self.llm_service.connect_to_llm()

        self.query_orchestrator = QueryOrchestrator(
            logger=self.logger, es_client=self.es_client, llm_service=self.llm_service
        )
        self.evaluation_orchestrator = EvaluationOrchestrator(
            logger=self.logger, llm_service=self.llm_service
        )
        self.feedback_orchestrator = FeedbackOrchestrator(db_manager=self.db_manager)
        self.cost_calculation_orchestrator = CostCalculationOrchestrator(
            logger=self.logger
        )

    def run(self, question):
        conversation_id = str(uuid.uuid4())

        # Process the query and get the response
        response, token_stats = self.query_orchestrator.process_query(question)

        # Evaluate the response
        evaluation_response, token_stats_evaluation = (
            self.evaluation_orchestrator.evaluate_response(question, response)
        )

        # Calculate the cost
        cost_rag = self.cost_calculation_orchestrator.calculate_cost(token_stats)
        cost_evaluation = self.cost_calculation_orchestrator.calculate_cost(
            token_stats_evaluation
        )
        total_cost = cost_rag + cost_evaluation

        # Save the conversation to the database
        self.db_manager.save_conversation(
            conversation_id=conversation_id, question=question, answer=response
        )

        return conversation_id, response, evaluation_response, total_cost
