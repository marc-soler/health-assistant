import uuid
from time import time

from logging_setup import LoggerSetup
from database_manager import DatabaseManager
from elasticsearch_indexer import ElasticsearchIndexer
from prompt_builder import PromptBuilder
import prompt_templates as templates
from search_service import SearchService
from llm_service import LLMService
from response_evaluator import ResponseEvaluator
from cost_calculator import CostCalculator


class QueryOrchestrator:
    """
    Orchestrates the process of querying the LLM, which includes searching the Elasticsearch index,
    building the query prompt, and interacting with the LLM service.

    Attributes:
        es_client (Elasticsearch): The Elasticsearch client used for searching the index.
        llm_service (LLMService): The LLM service used to query the language model.
    """

    def __init__(self, logger, search_service, llm_service):
        """
        Initializes the QueryOrchestrator with the given Elasticsearch client and LLM service.

        Args:
            es_client (Elasticsearch): The Elasticsearch client used for searching the index.
            llm_service (LLMService): The LLM service used to query the language model.
        """
        self.logger = logger
        self.search_service = search_service
        self.llm_service = llm_service

    def process_query(self, question):
        """
        Processes a query by searching the Elasticsearch index, building a prompt, and querying the LLM.

        Args:
            context (str): The context for the question, which may provide additional background information.
            question (str): The question to be asked to the LLM.

        Returns:
            tuple: A tuple containing the LLM's response and the token statistics from the query.
        """
        # Search the Elasticsearch index with the user's question
        search_results = self.search_service.search(query=question)

        # Build the prompt using search results and provided context
        question_prompt_builder = PromptBuilder(templates.QUESTION_PROMPT_TEMPLATE)
        context_data = question_prompt_builder.create_prompt_context(search_results)
        question_prompt = question_prompt_builder.build_prompt(
            question=question,
            answer=context_data["answer"],
            focus_area=context_data["focus_area"],
            source=context_data["source"],
        )

        # Query the LLM with the constructed prompt
        response, token_stats = self.llm_service.query_llm(prompt=question_prompt)

        return response, token_stats


class EvaluationOrchestrator:
    """
    Orchestrates the evaluation of the LLM's response, determining its relevance and gathering token statistics.

    Attributes:
        llm_service (LLMService): The LLM service used to query the language model for evaluation.
    """

    def __init__(self, logger, llm_service):
        """
        Initializes the EvaluationOrchestrator with the given LLM service.

        Args:
            llm_service (LLMService): The LLM service used to query the language model for evaluation.
        """
        self.logger = logger
        self.llm_service = llm_service

    def evaluate_response(self, question, answer):
        """
        Evaluates the relevance of the LLM's response to a given question.

        Args:
            question (str): The original question posed to the LLM.
            answer (str): The response generated by the LLM.

        Returns:
            tuple: A tuple containing the evaluation result (a dictionary) and the token statistics.
        """
        evaluator = ResponseEvaluator(
            logger=self.logger,
            llm_service=self.llm_service,
            prompt_builder=PromptBuilder(templates.EVALUATION_PROMPT_TEMPLATE),
        )
        evaluation_result, token_stats = evaluator.evaluate_relevance(question, answer)
        return evaluation_result, token_stats


class FeedbackOrchestrator:
    """
    Orchestrates the process of submitting user feedback, including like/dislike responses and additional comments.

    Attributes:
        db_manager (DatabaseManager): The database manager responsible for saving feedback data.
    """

    def __init__(self, db_manager):
        """
        Initializes the FeedbackOrchestrator with the given DatabaseManager.

        Args:
            db_manager (DatabaseManager): The database manager responsible for saving feedback data.
        """
        self.db_manager = db_manager

    def submit_feedback(self, conversation_id, feedback, additional_feedback):
        """
        Submits feedback for a given conversation, including a like/dislike and optional additional comments.

        Args:
            conversation_id (str): The unique identifier for the conversation.
            feedback (str): The feedback provided by the user, either "Like" or "Dislike".
            additional_feedback (str): Optional additional feedback provided by the user.
        """
        # Convert the feedback to a numerical value for storage
        feedback_value = 1 if feedback == "Like" else -1

        # Save the feedback to the database
        self.db_manager.save_feedback(
            conversation_id=conversation_id,
            feedback=feedback_value,
            timestamp=None,  # Assuming current timestamp is used if None
        )

        if additional_feedback:
            # Save additional feedback, if provided (implement saving as needed)
            self.db_manager.save_feedback(
                conversation_id=conversation_id,
                feedback=feedback_value,
                timestamp=None,  # Assuming current timestamp is used if None
            )


class CostCalculationOrchestrator:
    """
    Orchestrates the calculation of the cost associated with querying the LLM, based on token usage.

    Attributes:
        cost_calculator (CostCalculator): The cost calculator used to determine the OpenAI API cost.
    """

    def __init__(self, logger):
        """
        Initializes the CostCalculationOrchestrator with a CostCalculator.
        """
        self.cost_calculator = CostCalculator(logger=logger)

    def calculate_cost(self, token_stats):
        """
        Calculates the cost of the LLM query based on the provided token statistics.

        Args:
            token_stats (dict): A dictionary containing token usage statistics from the LLM query.

        Returns:
            float: The calculated cost of the LLM query.
        """
        cost = self.cost_calculator.calculate_openai_cost(token_stats)
        return cost


# Main Orchestrator that integrates all sub-orchestrators
class MainOrchestrator:
    def __init__(self):
        logger_setup = LoggerSetup()
        self.logger = logger_setup.get_logger()

        self.db_manager = DatabaseManager(logger=self.logger)
        self._initialize_db_once()

        self.indexer = ElasticsearchIndexer(logger=self.logger)
        self.es_client, self.index_name = self.indexer.load_and_index_data()

        self.search_service = SearchService(
            logger=self.logger, es_client=self.indexer.es_client
        )

        self.llm_service = LLMService(logger=self.logger)
        self.llm_service.connect_to_llm()

        self.query_orchestrator = QueryOrchestrator(
            logger=self.logger,
            search_service=self.search_service,
            llm_service=self.llm_service,
        )
        self.evaluation_orchestrator = EvaluationOrchestrator(
            logger=self.logger, llm_service=self.llm_service
        )
        self.feedback_orchestrator = FeedbackOrchestrator(db_manager=self.db_manager)
        self.cost_calculation_orchestrator = CostCalculationOrchestrator(
            logger=self.logger
        )

    def _initialize_db_once(self):
        """Initialize the database only if it hasn't been initialized before."""
        if not self.db_manager.is_db_initialized():
            self.db_manager.init_db()
        else:
            if self.logger is not None:
                self.logger.info("Database already initialized.")

    def run(self, question):
        conversation_id = str(uuid.uuid4())
        t0 = time()

        # Process the query and get the response
        response, token_stats = self.query_orchestrator.process_query(question)

        # Evaluate the response
        evaluation_response, token_stats_evaluation = (
            self.evaluation_orchestrator.evaluate_response(question, response)
        )
        t1 = time()
        took = t1 - t0

        # Calculate the cost
        cost_rag = self.cost_calculation_orchestrator.calculate_cost(token_stats)
        cost_evaluation = self.cost_calculation_orchestrator.calculate_cost(
            token_stats_evaluation
        )
        openai_cost = cost_rag + cost_evaluation

        # Save the conversation to the database
        answer_data = {
            "answer": response,
            "model_used": "gpt-4o-mini",
            "response_time": took,
            "relevance": evaluation_response.get("Relevance", "UNKNOWN"),  # type: ignore
            "relevance_explanation": evaluation_response.get(  # type: ignore
                "Explanation", "Failed to parse evaluation"
            ),
            "prompt_tokens": token_stats["prompt_tokens"],
            "completion_tokens": token_stats["completion_tokens"],
            "total_tokens": token_stats["total_tokens"],
            "eval_prompt_tokens": token_stats_evaluation["prompt_tokens"],  # type: ignore
            "eval_completion_tokens": token_stats_evaluation["completion_tokens"],  # type: ignore
            "eval_total_tokens": token_stats_evaluation["total_tokens"],  # type: ignore
            "openai_cost": openai_cost,
        }
        self.db_manager.save_conversation(
            conversation_id=conversation_id, question=question, answer=answer_data
        )

        return conversation_id, response, evaluation_response, openai_cost

    def close_rag(self):
        """
        Closes any initialised connections: Postgres database, Elasticsearch, and LLM client.
        """
        self.db_manager.close_connection()
        self.es_client.close()
        self.llm_service.close_llm_client()
        if self.logger is not None:
            self.logger.info("RAD system connections closed.")
